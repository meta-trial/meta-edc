{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# uv sync --group develop --group notebook\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dj_notebook import activate\n",
    "\n",
    "env_file = os.environ[\"META_ENV\"]\n",
    "reports_folder = Path(os.environ[\"META_REPORTS_FOLDER\"])\n",
    "analysis_folder = Path(os.environ[\"META_ANALYSIS_FOLDER\"])\n",
    "pharmacy_folder = Path(os.environ[\"META_PHARMACY_FOLDER\"])\n",
    "plus = activate(dotenv_file=env_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from django.apps import apps as django_apps\n",
    "from django.db.models import Count\n",
    "from django_pandas.io import read_frame\n",
    "from edc_appointment.analytics import get_appointment_df\n",
    "from edc_appointment.constants import NEW_APPT\n",
    "from edc_pdutils.dataframes.get_subject_visit import convert_visit_code_to_float\n",
    "from edc_pharmacy.analytics import get_next_scheduled_visit_for_subjects_df\n",
    "from edc_pharmacy.analytics.dataframes import no_stock_for_subjects_df\n",
    "from edc_pharmacy.models import (\n",
    "    Allocation,\n",
    "    Container,\n",
    "    Lot,\n",
    "    OrderItem,\n",
    "    ReceiveItem,\n",
    "    Stock,\n",
    "    StockRequest,\n",
    ")\n",
    "from edc_registration.models import RegisteredSubject\n",
    "from edc_visit_schedule.models import SubjectScheduleHistory\n",
    "from edc_visit_schedule.site_visit_schedules import site_visit_schedules\n",
    "from great_tables import GT, html, loc, style\n",
    "from PIL import Image\n",
    "\n",
    "from meta_rando.models import RandomizationList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edc_model_to_dataframe import read_frame_edc\n",
    "\n",
    "from meta_subject.models import FollowupExamination\n",
    "\n",
    "df = read_frame_edc(\n",
    "    FollowupExamination.objects.all(), drop_sys_columns=True, drop_action_item_columns=True\n",
    ")\n",
    "df = df.replace(\"none\", pd.NA)\n",
    "df = df.replace(\"none\", pd.NA)\n",
    "df = df.fillna(pd.NA)\n",
    "convert_visit_code_to_float(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from_appt_date = datetime(2025, 8, 10)\n",
    "last_appt_date = datetime(2026, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from edc_analytics.stata import get_stata_labels_from_model\n",
    "#\n",
    "# df = df[[\"subject_identifier\", \"subject_visit_id\", \"report_datetime\", \"visit_code\", \"site_id\", \"site_name\", \"visit_reason\", \"symptoms\",\"symptoms_detail\", \"symptoms_sought_care\", \"symptoms_g3\", \"symptoms_g4\", \"comment\"]].copy().reset_index(drop=True)\n",
    "#\n",
    "# df = df.astype(\n",
    "#     {col: \"Float64\" for col in df.select_dtypes(include=[\"float\", \"float64\"]).columns}\n",
    "# )\n",
    "# df_meds = df.astype(\n",
    "#     {col: \"Int64\" for col in df.select_dtypes(include=[\"int\", \"int64\"]).columns}\n",
    "# )\n",
    "# df = df.astype(\n",
    "#     {\n",
    "#         col: \"datetime64[ns]\"\n",
    "#         for col in df.select_dtypes(include=[\"datetime\", \"datetime64\"]).columns\n",
    "#     }\n",
    "# )\n",
    "# df = df.astype(\n",
    "#     {\n",
    "#         col: str\n",
    "#         for col in df.select_dtypes(include=[\"object\"]).columns\n",
    "#     }\n",
    "# )\n",
    "# df = df.fillna(pd.NA)\n",
    "#\n",
    "# variable_labels = {}\n",
    "# variable_labels.update(**get_stata_labels_from_model(df, model=\"meta_subject.followupexamination\", suffix=None))\n",
    "#\n",
    "# df.to_stata(\n",
    "#     path=analysis_folder / \"followupexamination.dta\",\n",
    "#     variable_labels=variable_labels,\n",
    "#     version=118,\n",
    "#     write_index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_great_table(df: pd.DataFrame, title: str, footnote: str | None = None):\n",
    "    return (\n",
    "        GT(df)\n",
    "        .tab_header(title=html(title))\n",
    "        .cols_align(align=\"left\", columns=[0])\n",
    "        .cols_align(align=\"right\", columns=list(range(1, len(df.columns))))\n",
    "        .opt_stylize(style=5)\n",
    "        .opt_row_striping(row_striping=False)\n",
    "        .opt_vertical_padding(scale=1.2)\n",
    "        .opt_horizontal_padding(scale=1.0)\n",
    "        .tab_options(\n",
    "            stub_background_color=\"white\",\n",
    "            row_group_border_bottom_style=\"hidden\",\n",
    "            row_group_padding=0.5,\n",
    "            row_group_background_color=\"white\",\n",
    "            table_background_color=\"white\",\n",
    "            table_font_size=12,\n",
    "        )\n",
    "        .tab_style(\n",
    "            style=[style.fill(color=\"white\"), style.text(color=\"black\")],\n",
    "            locations=loc.body(\n",
    "                columns=list(range(len(df.columns))), rows=list(range(0, len(df)))\n",
    "            ),\n",
    "        )\n",
    "        .tab_style(\n",
    "            style=[style.fill(color=\"lightgrey\"), style.text(color=\"black\")],\n",
    "            locations=loc.body(columns=list(range(len(df.columns))), rows=[len(df) - 1]),\n",
    "        )\n",
    "        .tab_source_note(source_note=html(footnote or \"\"))\n",
    "        .tab_style(\n",
    "            style=style.text(color=\"black\", size=\"small\"),\n",
    "            locations=loc.footer(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rando\n",
    "df_rando = read_frame(\n",
    "    RandomizationList.objects.values(\"subject_identifier\", \"assignment\").filter(\n",
    "        subject_identifier__isnull=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get appointments\n",
    "df_appt = get_appointment_df()\n",
    "print(\n",
    "    f\"{len(df_appt[(df_appt.appt_status == NEW_APPT) & (df_appt.appt_datetime >= start_from_appt_date) & (df_appt.appt_datetime < last_appt_date) & (df_appt.visit_code != 1480.0)])} appointments after filtering\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of subjects still on the 'schedule' schedule\n",
    "# use SubjectScheduleHistory where offschedule_datetime is null\n",
    "df_subject_schedule = read_frame(\n",
    "    SubjectScheduleHistory.objects.values(\n",
    "        \"subject_identifier\",\n",
    "        \"visit_schedule_name\",\n",
    "        \"schedule_name\",\n",
    "        \"onschedule_datetime\",\n",
    "        \"offschedule_datetime\",\n",
    "    ).filter(offschedule_datetime__isnull=True, schedule_name=\"schedule\")\n",
    ")\n",
    "\n",
    "print(f\"{len(df_subject_schedule)} subjects currently onstudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now merge with the unfiltered df_appt\n",
    "df_main = df_subject_schedule.merge(\n",
    "    df_appt[\n",
    "        [\n",
    "            \"appointment_id\",\n",
    "            \"subject_identifier\",\n",
    "            \"visit_code\",\n",
    "            \"visit_code_str\",\n",
    "            \"appt_datetime\",\n",
    "            \"baseline_datetime\",\n",
    "            \"endline_visit_code\",\n",
    "            \"visit_code_sequence\",\n",
    "            \"appt_status\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"subject_identifier\",\n",
    "    how=\"left\",\n",
    ")\n",
    "# exclude unscheduled,\n",
    "df_main = df_main[\n",
    "    (df_main.visit_code_sequence == 0)\n",
    "    & (df_main.visit_schedule_name == \"visit_schedule\")\n",
    "    & (df_main.schedule_name == \"schedule\")\n",
    "    & (df_main.visit_code < 2000.0)\n",
    "    & (df_main.appt_status == NEW_APPT)\n",
    "].copy()\n",
    "print(f\"{len(df_main)} new appointments for subjects on study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of appointments before extended all subjects out to 48m\n",
    "df_grouped = (\n",
    "    df_main[\n",
    "        (df_main.appt_datetime >= start_from_appt_date)\n",
    "        & (df_main.appt_datetime < last_appt_date)\n",
    "        & (df_main.visit_code != 1480.0)\n",
    "    ]\n",
    "    .visit_code.value_counts()\n",
    "    .reset_index(name=\"appointments\")\n",
    "    .sort_values(by=\"visit_code\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_grouped[\"cumsum\"] = df_grouped.appointments.cumsum()\n",
    "df_grouped[\"cumsum\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extend everyone to 48 months.\n",
    "# Subjects are in the process of consenting for extended\n",
    "# followup. Assume ALL have done so by filling in all\n",
    "# subject schedules to 48m\n",
    "\n",
    "# pivot\n",
    "df_pivot = df_main[\n",
    "    (df_main.visit_code_sequence == 0) & (df_main.visit_code < 2000.0)\n",
    "].pivot_table(\n",
    "    index=\"subject_identifier\", columns=\"visit_code\", values=\"appt_datetime\", aggfunc=\"count\"\n",
    ")\n",
    "df_pivot.fillna(0, inplace=True)\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot.rename_axis(\"\", axis=\"columns\", inplace=True)\n",
    "\n",
    "# melt\n",
    "df_pivot = df_pivot.melt(\n",
    "    id_vars=\"subject_identifier\", var_name=\"visit_code\", value_name=\"exists\"\n",
    ")\n",
    "df_pivot[\"visit_code\"] = df_pivot[\"visit_code\"].astype(float)\n",
    "df_pivot.sort_values([\"subject_identifier\", \"visit_code\"], ascending=True, inplace=True)\n",
    "df_pivot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge in baseline_datetime\n",
    "df_baseline = df_appt[df_appt.visit_code == 1000.0][\n",
    "    [\"subject_identifier\", \"baseline_datetime\"]\n",
    "]\n",
    "df_pivot = df_pivot.merge(df_baseline, on=[\"subject_identifier\"], how=\"left\")\n",
    "df_pivot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge df_main back in\n",
    "df_pivot = df_pivot.merge(\n",
    "    df_main[[\"subject_identifier\", \"visit_code\", \"appt_datetime\", \"appt_status\"]],\n",
    "    on=[\"subject_identifier\", \"visit_code\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.query(\"visit_code==1480.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_pivot[(df_pivot.appt_datetime>=datetime(2025,1,1)) & (df_pivot.visit_code==MONTH48)])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend no one!\n",
    "# df_pivot = df_pivot[df_pivot.exists==1].copy()\n",
    "# df_pivot.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add appointments do not have an appt_datetime, so calculate\n",
    "# using the visit schedule relative to baseline_datetime\n",
    "visit_schedule = site_visit_schedules.get_visit_schedule(\"visit_schedule\")\n",
    "schedule = visit_schedule.schedules.get(\"schedule\")\n",
    "mapping = {k: visit.rbase for k, visit in schedule.visits.items()}\n",
    "\n",
    "\n",
    "def estimate_appt_datetime(row):\n",
    "    if pd.isna(row[\"appt_datetime\"]):\n",
    "        row[\"appt_datetime\"] = row[\"baseline_datetime\"] + mapping.get(\n",
    "            str(int(row[\"visit_code\"]))\n",
    "        )\n",
    "    return row\n",
    "\n",
    "\n",
    "df_pivot = df_pivot.apply(estimate_appt_datetime, axis=1)\n",
    "df_pivot.sort_values(by=[\"subject_identifier\", \"visit_code\"], ascending=True, inplace=True)\n",
    "df_pivot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge in assignment\n",
    "df_pivot = df_pivot.merge(df_rando, on=\"subject_identifier\", how=\"left\")\n",
    "df_pivot.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# flag added appointments as NEW\n",
    "df_pivot.loc[df_pivot.exists == 0.0, \"appt_status\"] = NEW_APPT\n",
    "\n",
    "print(f\"{len(df_pivot)} appointments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subject_appointments is a dataframe of appointments\n",
    "# - only include NEW appointments\n",
    "# - only include appts between today (2025,4,4) and before (2026,3,1).\n",
    "# - exclude the last visit (48m) since no meds are dispensed then.\n",
    "df_subject_appointments = df_pivot[\n",
    "    (df_pivot.appt_status == NEW_APPT)\n",
    "    & (df_pivot.appt_datetime >= start_from_appt_date)\n",
    "    & (df_pivot.appt_datetime < last_appt_date)\n",
    "    & (df_pivot.visit_code != 1480.0)\n",
    "].copy()\n",
    "print(f\"{len(df_subject_appointments)} appointments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_subject_appointments.subject_identifier.nunique()\n",
    "print(f\"{n} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(df_subject_appointments[df_subject_appointments.appt_datetime>=datetime(2026,1,1)])/36)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the appointments\n",
    "df_summary = (\n",
    "    df_subject_appointments.visit_code.value_counts()\n",
    "    .reset_index(name=\"appointments\")\n",
    "    .sort_values(by=[\"visit_code\"], ascending=True)\n",
    ")\n",
    "df_summary[\"cumsum\"] = df_summary.appointments.cumsum()\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_subject_appointments.assignment.value_counts(dropna=False).reset_index()\n",
    "df.rename(columns={\"count\": \"appointments\"}, inplace=True)\n",
    "df[\"bottles\"] = df.appointments * 3\n",
    "df[\"tablets\"] = df.bottles * 128\n",
    "\n",
    "# we need this many bottles / tablets by assignment\n",
    "# filter\n",
    "df.loc[len(df)] = {\n",
    "    \"appointments\": df.appointments.sum(),\n",
    "    \"bottles\": df.bottles.sum(),\n",
    "    \"tablets\": df.tablets.sum(),\n",
    "}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = get_great_table(\n",
    "    df,\n",
    "    f\"Table 1: IMP Bottles of 128 needed<BR><small>from {start_from_appt_date.strftime('%Y-%m-%d')} to < {last_appt_date.strftime('%Y-%m-%d')}</small>\",\n",
    "    footnote=(\n",
    "        \"<ol>\"\n",
    "        \"<li>Assumes all participants consent for extended followup.\"\n",
    "        \"<li>Need 3 bottles every three months\"\n",
    "        \"<li>48m appointment is excluded\"\n",
    "        f\"<li>Only includes appointments scheduled before {last_appt_date.strftime('%Y-%m-%d')}.\"\n",
    "        \"</ol>\"\n",
    "    ),\n",
    ")\n",
    "gt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as png\n",
    "gt.save(analysis_folder / \"pharmacy_tbl1.png\")\n",
    "# export to PDF\n",
    "image = Image.open(analysis_folder / \"pharmacy_tbl1.png\")\n",
    "image = image.resize((image.width * 6, image.height * 6), Image.LANCZOS)\n",
    "image.save(\n",
    "    analysis_folder / \"pharmacy_tbl1.pdf\", \"PDF\", resolution=800, optimize=True, quality=95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\", disable_numparse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets look at the stock\n",
    "df_stock = read_frame(\n",
    "    Stock.objects.values(\n",
    "        \"code\",\n",
    "        \"lot_id\",\n",
    "        \"container__name\",\n",
    "        \"confirmation\",\n",
    "        \"allocation\",\n",
    "        \"dispenseitem\",\n",
    "        \"qty_in\",\n",
    "        \"qty_out\",\n",
    "        \"unit_qty_in\",\n",
    "        \"unit_qty_out\",\n",
    "    ).all(),\n",
    "    verbose=False,\n",
    ")\n",
    "df_stock = df_stock.fillna(pd.NA)\n",
    "\n",
    "# merge in assignment\n",
    "df_lot = read_frame(Lot.objects.values(\"id\", \"assignment__name\").all(), verbose=False)\n",
    "df_lot.rename(columns={\"id\": \"lot_id\", \"assignment__name\": \"assignment\"}, inplace=True)\n",
    "df_stock = df_stock.merge(df_lot[[\"lot_id\", \"assignment\"]], on=\"lot_id\", how=\"left\")\n",
    "df_stock.rename(columns={\"container__name\": \"container\"}, inplace=True)\n",
    "df_stock.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in container columns\n",
    "df_container = read_frame(Container.objects.all())\n",
    "df_container.rename(\n",
    "    columns={\n",
    "        \"name\": \"container\",\n",
    "        \"display_name\": \"container_display_name\",\n",
    "        \"units\": \"container_units\",\n",
    "        \"qty\": \"container_qty\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df_stock = df_stock.merge(\n",
    "    df_container[\n",
    "        [\n",
    "            \"container\",\n",
    "            \"container_display_name\",\n",
    "            \"container_type\",\n",
    "            \"container_units\",\n",
    "            \"container_qty\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"container\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_stock.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# calculate bal\n",
    "df_stock[\"bal\"] = df_stock[\"unit_qty_in\"] - df_stock[\"unit_qty_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the balance of tablets decanted to bottles by assignment (on the EDC)\n",
    "df2 = (\n",
    "    df_stock[df_stock.container_display_name == \"Bottle 128\"]\n",
    "    .groupby(by=[\"assignment\"])\n",
    "    .bal.agg(\"sum\")\n",
    "    .reset_index()\n",
    ")\n",
    "df2.loc[len(df2)] = {\"bal\": df2.bal.sum()}\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some bottles, as of today, have not been captured in the system\n",
    "# here is an estimate of what has been decanted into bottles but not labelled.\n",
    "# in the system, these tablets would appear on the EDC as still in buckets\n",
    "df3 = df2.copy()\n",
    "df3 = df3.drop(len(df3) - 1)\n",
    "placebo_unlabelled = 0  # 21*128*128\n",
    "active_unlabelled = 0  # 25*191*128\n",
    "\n",
    "# adding in the estimates, this is about what we have bottled\n",
    "df3.loc[df3.assignment == \"placebo\", \"bal\"] += placebo_unlabelled\n",
    "df3.loc[df3.assignment == \"active\", \"bal\"] += active_unlabelled\n",
    "df3.loc[len(df3)] = {\"bal\": df3.bal.sum()}\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = get_great_table(\n",
    "    df3,\n",
    "    f\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Table 2: IMP tablets in stock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<BR><small>data downloaded on {start_from_appt_date.strftime('%Y-%m-%d')}</small>\",\n",
    "    # footnote=\"Includes recently decanted but unlabelled bottles\"\n",
    ")\n",
    "gt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as png\n",
    "gt.save(analysis_folder / \"pharmacy_tbl2.png\")\n",
    "# export to PDF\n",
    "image = Image.open(analysis_folder / \"pharmacy_tbl2.png\")\n",
    "image = image.resize((image.width * 6, image.height * 6), Image.LANCZOS)\n",
    "image.save(\n",
    "    analysis_folder / \"pharmacy_tbl2.pdf\", \"PDF\", resolution=800, optimize=True, quality=95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(df3, headers=\"keys\", tablefmt=\"fancy_grid\", disable_numparse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: ordered\n",
    "df_orderitems = read_frame(OrderItem.objects.all())\n",
    "df_orderitems.qty.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: received\n",
    "df_received_items = read_frame(ReceiveItem.objects.all())\n",
    "df_received_items.unit_qty.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: received into stock\n",
    "df_stock[df_stock.container_type == \"bucket\"].unit_qty_in.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: decanted from buckets into bottles\n",
    "df_stock[df_stock.container_type == \"bucket\"].unit_qty_out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: total in bottles\n",
    "df_stock[df_stock.container_type == \"Bottle\"].unit_qty_in.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tablets: total bottles available / not yet dispensed BY ASSIGNMENT\n",
    "# the total matches the total above for column \"bal\"\n",
    "df4 = (\n",
    "    df_stock[\n",
    "        (df_stock.container_type == \"Bottle\")\n",
    "        & ~(df_stock.confirmation.isna())\n",
    "        & ~(df_stock.dispenseitem.isna())\n",
    "    ]\n",
    "    .groupby(by=[\"assignment\"])\n",
    "    .unit_qty_in.sum()\n",
    "    .reset_index()\n",
    ")\n",
    "df4[\"subtotal\"] = np.nan\n",
    "df4.loc[len(df4)] = {\"subtotal\": df4.unit_qty_in.sum()}\n",
    "df[\"dispensed\"] = True\n",
    "\n",
    "df5 = (\n",
    "    df_stock[\n",
    "        (df_stock.container_type == \"Bottle\")\n",
    "        & ~(df_stock.confirmation.isna())\n",
    "        & (df_stock.dispenseitem.isna())\n",
    "    ]\n",
    "    .groupby(by=[\"assignment\"])\n",
    "    .unit_qty_in.sum()\n",
    "    .reset_index()\n",
    ")\n",
    "df5.loc[df5.assignment == \"placebo\", \"unit_qty_in\"] += placebo_unlabelled\n",
    "df5.loc[df5.assignment == \"active\", \"unit_qty_in\"] += active_unlabelled\n",
    "df5[\"subtotal\"] = np.nan\n",
    "df5.loc[len(df5)] = {\"subtotal\": df5.unit_qty_in.sum()}\n",
    "df5[\"dispensed\"] = False\n",
    "\n",
    "df6 = pd.concat([df4, df5])\n",
    "df6[\"total\"] = np.nan\n",
    "df6.reset_index(drop=True, inplace=True)\n",
    "df6.loc[len(df6)] = {\"total\": df6.subtotal.sum()}\n",
    "df6 = df6[[\"dispensed\", \"assignment\", \"unit_qty_in\", \"subtotal\", \"total\"]]\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_visit_schedule.constants import MONTH36\n",
    "\n",
    "df_appt[\n",
    "    (df_appt.visit_code_str == MONTH36)\n",
    "    & (df_appt.appt_datetime >= datetime(2024, 12, 15))\n",
    "    & (df_appt.appt_status == NEW_APPT)\n",
    "    & (df_appt.appt_datetime <= datetime(2026, 2, 28))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subjects_where_stock_on_site(stock_request: StockRequest, df: pd.DataFrame):\n",
    "    stock_model_cls = django_apps.get_model(\"edc_pharmacy.Stock\")\n",
    "    qs_stock = (\n",
    "        stock_model_cls.objects.values(\n",
    "            \"allocation__registered_subject__subject_identifier\", \"code\"\n",
    "        )\n",
    "        .filter(location=stock_request.location, qty=1)\n",
    "        .annotate(count=Count(\"allocation__registered_subject__subject_identifier\"))\n",
    "    )\n",
    "    df_stock = read_frame(qs_stock)\n",
    "    df_stock = df_stock.rename(\n",
    "        columns={\n",
    "            \"allocation__registered_subject__subject_identifier\": \"subject_identifier\",\n",
    "            \"count\": \"stock_qty\",\n",
    "        }\n",
    "    )\n",
    "    if not df.empty and not df_stock.empty:\n",
    "        df_subject = df.copy()\n",
    "        df_subject[\"code\"] = None\n",
    "        df = df.merge(df_stock, on=\"subject_identifier\", how=\"left\")\n",
    "        for index, row in df.iterrows():\n",
    "            qty_needed = stock_request.containers_per_subject - len(\n",
    "                df[df.subject_identifier == row.subject_identifier]\n",
    "            )\n",
    "            if qty_needed > 0:\n",
    "                for _ in range(0, qty_needed):\n",
    "                    df = pd.concat([df, df_subject])\n",
    "    else:\n",
    "        df[\"code\"] = None\n",
    "    df[\"stock_qty\"] = 0.0\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_null_rows(df, qty_needed):\n",
    "    padded_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        customer = row[\"subject\"]\n",
    "        products = row[\"product_code\"]\n",
    "        # Pad the products list with None to make its length x\n",
    "        products += [None] * (qty_needed - len(products))\n",
    "        # Create x rows for each customer\n",
    "        for product in products:\n",
    "            padded_data.append({\"customer\": customer, \"product_code\": product})\n",
    "    return pd.DataFrame(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = \"5455cf66-b8e5-449c-a1e8-24d3325026d7\"\n",
    "stock_request = StockRequest.objects.get(pk=pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = get_next_scheduled_visit_for_subjects_df(stock_request)\n",
    "df_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_subjects.copy()\n",
    "stock_model_cls = django_apps.get_model(\"edc_pharmacy.Stock\")\n",
    "qs_stock = (\n",
    "    stock_model_cls.objects.values(\n",
    "        \"allocation__registered_subject__subject_identifier\", \"code\"\n",
    "    )\n",
    "    .filter(location=stock_request.location, qty=1)\n",
    "    .annotate(count=Count(\"allocation__registered_subject__subject_identifier\"))\n",
    ")\n",
    "df_stock = read_frame(qs_stock)\n",
    "df_stock = df_stock.rename(\n",
    "    columns={\n",
    "        \"allocation__registered_subject__subject_identifier\": \"subject_identifier\",\n",
    "        \"count\": \"stock_qty\",\n",
    "    }\n",
    ")\n",
    "df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(df_stock, on=\"subject_identifier\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and not df_stock.empty:\n",
    "    df_subject = df.copy()\n",
    "    df_subject[\"code\"] = None\n",
    "    df = df.merge(df_stock, on=\"subject_identifier\", how=\"left\")\n",
    "    for index, row in df.iterrows():\n",
    "        qty_needed = stock_request.containers_per_subject - len(\n",
    "            df[df.subject_identifier == row.subject_identifier]\n",
    "        )\n",
    "        if qty_needed > 0:\n",
    "            for _ in range(0, qty_needed):\n",
    "                df = pd.concat([df, df_subject])\n",
    "else:\n",
    "    df[\"code\"] = None\n",
    "df[\"stock_qty\"] = 0.0\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.index.repeat(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty and not df_stock.empty:\n",
    "    df = df.merge(df_stock, on=\"subject_identifier\", how=\"left\")\n",
    "else:\n",
    "    df[\"code\"] = None\n",
    "df[\"stock_qty\"] = 0.0\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_subjects_where_stock_on_site(stock_request, df_subjects)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_instock = df[~df.code.isna()]\n",
    "df_instock = df_instock.reset_index(drop=True)\n",
    "df_instock = df_instock.sort_values(by=[\"subject_identifier\"])\n",
    "\n",
    "df_nostock = df[df.code.isna()]\n",
    "df_nostock = df_nostock.reset_index(drop=True)\n",
    "df_nostock = df_nostock.loc[\n",
    "    df_nostock.index.repeat(stock_request.containers_per_subject)\n",
    "].reset_index(drop=True)\n",
    "df_nostock = df_nostock.sort_values(by=[\"subject_identifier\"])\n",
    "df_nostock[\"code\"] = df_nostock[\"code\"].fillna(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stock_for_subjects_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedule = read_frame(\n",
    "    SubjectScheduleHistory.objects.values(\n",
    "        \"subject_identifier\", \"visit_schedule_name\", \"schedule_name\", \"offschedule_datetime\"\n",
    "    ).all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_schedule = df_schedule[\n",
    "    (df_schedule.visit_schedule_name == \"visit_schedule\")\n",
    "    & (df_schedule.schedule_name == \"schedule\")\n",
    "    & df_schedule.offschedule_datetime.isna()\n",
    "]\n",
    "df_schedule.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock = read_frame(Stock.objects.all(), verbose=False)\n",
    "df_stock_on_site = df_stock[\n",
    "    (df_stock.confirmed_at_site == True) & (df_stock.dispensed == False)\n",
    "].copy()\n",
    "df_stock_on_site.reset_index(drop=True, inplace=True)\n",
    "df_stock_on_site = df_stock_on_site.drop(columns=[\"subject_identifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allocation = read_frame(\n",
    "    Allocation.objects.values(\"id\", \"registered_subject\").all(), verbose=False\n",
    ")\n",
    "df_rs = read_frame(\n",
    "    RegisteredSubject.objects.values(\"id\", \"subject_identifier\").all(), verbose=False\n",
    ")\n",
    "df_allocation = df_allocation.merge(\n",
    "    df_rs[[\"id\", \"subject_identifier\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"registered_subject\",\n",
    "    right_on=\"id\",\n",
    "    suffixes=[\"_allocation\", \"_rs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock_on_site = df_stock_on_site.merge(\n",
    "    df_allocation[[\"id_allocation\", \"subject_identifier\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"allocation\",\n",
    "    right_on=\"id_allocation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df_schedule[[\"subject_identifier\", \"offschedule_datetime\"]],\n",
    "    df_stock_on_site,\n",
    "    on=\"subject_identifier\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df = (\n",
    "    df[df.code.isna()][[\"subject_identifier\"]]\n",
    "    .sort_values(by=[\"subject_identifier\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appt = get_next_scheduled_visit_for_subjects_df()\n",
    "df_appt = df_appt[\n",
    "    [\"subject_identifier\", \"site_id\", \"visit_code\", \"appt_datetime\", \"baseline_datetime\"]\n",
    "].copy()\n",
    "df_appt.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_appt, how=\"left\", on=\"subject_identifier\")\n",
    "df = df[(df.appt_datetime.notna())]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_now = pd.Timestamp.utcnow().tz_localize(None)\n",
    "df[\"relative_days\"] = (df.appt_datetime - utc_now).dt.days\n",
    "df_final = df[(df.relative_days >= -105)].copy()\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegisteredSubject.objects.filter(site_id=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
