{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from remote_read_sql import get_db_connection\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from clinicedc_constants import MICROMOLES_PER_LITER\n",
    "from clinicedc_utils import EgfrCockcroftGault\n",
    "from edc_pdutils.utils import convert_visit_code_to_float\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change as needed\n",
    "my_cnf_path = Path(\"~/.my.cnf\")\n",
    "my_cnf_connection_name = \"client\"\n",
    "data_folder = Path(\"~/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Documents - igh.respond-africa/META2-data/\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn_opts = dict(my_cnf_path=my_cnf_path, connection_name=my_cnf_connection_name, db_name=\"meta2_production\", local_bind_port=3306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql statements\n",
    "sql_rft = \"select subject_visit_id, creatinine_value, creatinine_units, creatinine_abnormal, creatinine_reportable, creatinine_grade, egfr_value, egfr_units, egfr_abnormal, egfr_reportable, egfr_grade from meta_subject_bloodresultsrft\"\n",
    "sql_visit = \"select id, subject_identifier, visit_code, visit_code_sequence, report_datetime, site_id from meta_subject_subjectvisit\"\n",
    "sql_consent = \"select subject_identifier, gender, dob from meta_consent_subjectconsent\"\n",
    "sql_physical_exam = \"select subject_visit_id, weight from meta_subject_physicalexam\"\n",
    "sql_followupvitals = \"select subject_visit_id, weight from meta_subject_followupvitals\"\n",
    "sql_screen = \"select screening_identifier, subject_identifier, weight as weight_scr, selection_method from meta_screening_subjectscreening\"\n",
    "sql_dd = \"select model, field_name, field_type, `default`, prompt from edc_data_manager_datadictionary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in table data\n",
    "with get_db_connection(**db_conn_opts) as db_conn:\n",
    "    df_rft = pd.read_sql(sql_rft, con=db_conn)\n",
    "    df_visit = pd.read_sql(sql_visit, con=db_conn)\n",
    "    df_consent = pd.read_sql(sql_consent, con=db_conn)\n",
    "    df_physical_exam = pd.read_sql(sql_physical_exam, con=db_conn)\n",
    "    df_followupvitals = pd.read_sql(sql_followupvitals, con=db_conn)\n",
    "    df_screen = pd.read_sql(sql_screen, con=db_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_screen[\"selection_method\"] = df_screen[\"selection_method\"].replace('purposively_selected', 'purposeful')\n",
    "df_screen[\"selection_method\"] = df_screen[\"selection_method\"].replace('random_sampling', 'random')\n",
    "cat_type = pd.CategoricalDtype(categories=[\"purposeful\", \"random\"], ordered=True)\n",
    "df_screen[\"selection_method\"] = df_screen[\"selection_method\"].astype(cat_type)\n",
    "df_screen.selection_method.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rando_meta2.csv\n",
    "df_rando = pd.read_csv(data_folder / \"rando\" / \"rando_meta2.csv\",sep=\"|\", encoding=\"utf8\")\n",
    "df_rando[\"assignment\"] = df_rando[\"assignment\"].replace('placebo', 'control')\n",
    "df_rando[\"assignment\"] = df_rando[\"assignment\"].replace('active', 'treatment')\n",
    "assignment_type = pd.CategoricalDtype(categories=[\"control\", \"treatment\"], ordered=True)\n",
    "df_rando[\"assignment\"] = df_rando[\"assignment\"].astype(assignment_type)\n",
    "df_rando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert visit code to a float\n",
    "df_visit = df_visit.rename(columns={\"id\": \"subject_visit_id\", \"report_datetime\": \"visit_datetime\"})\n",
    "df_visit[\"visit_code_str\"] = df_visit[\"visit_code\"]\n",
    "convert_visit_code_to_float(df_visit)\n",
    "\n",
    "# convert consent DOB to a datetime\n",
    "df_consent[\"dob\"] = df_consent['dob'].apply(pd.to_datetime, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to get all longitudunal weight values per subject\n",
    "df_weight = pd.merge(df_physical_exam, df_followupvitals, on=[\"subject_visit_id\"], how=\"outer\")\n",
    "df_weight = df_visit[[\"subject_visit_id\", \"subject_identifier\", \"visit_datetime\"]].merge(df_weight, on=\"subject_visit_id\", how=\"left\")\n",
    "df_weight[\"weight\"] = df_weight['weight_x'].combine_first(df_weight['weight_y'])\n",
    "\n",
    "df_weight[\"weight_imputed\"] = df_weight.groupby(by=[\"subject_identifier\"])['weight'].ffill()\n",
    "df_last = df_weight[df_weight[\"weight_imputed\"].notna()].groupby('subject_identifier').last(numeric_only=True).reset_index()\n",
    "df_first = df_weight[df_weight[\"weight_imputed\"].notna()].groupby('subject_identifier').first(numeric_only=True).reset_index()\n",
    "df_b2d = pd.merge(df_first[[\"subject_identifier\", \"weight_imputed\"]], df_last[[\"subject_identifier\", \"weight_imputed\"]], on='subject_identifier', how=\"outer\", suffixes=(\"_baseline\", \"_endline\"))\n",
    "df_b2d = df_b2d.rename(columns={\"weight_imputed_baseline\": \"weight_baseline_imputed\", \"weight_imputed_endline\":\"weight_endline_imputed\"})\n",
    "df_weight = df_weight.merge(df_b2d, on=\"subject_identifier\", how=\"left\").sort_values(by=[\"subject_identifier\"]).reset_index(drop=True)\n",
    "df_weight[\"weight_change_b2e_imputed\"] = df_weight[\"weight_endline_imputed\"] - df_weight[\"weight_baseline_imputed\"]\n",
    "df_weight = df_weight.sort_values(by=[\"subject_identifier\", \"visit_datetime\"]).reset_index(drop=True)\n",
    "df_weight['weight_change'] = df_weight.groupby('subject_identifier')['weight_imputed'].diff()\n",
    "df_weight['weight_change'] = df_weight.weight_change.apply(lambda x: 0.0 if pd.isna(x) else x)\n",
    "df_weight = df_weight.drop(columns=[\"subject_identifier\", \"visit_datetime\", \"weight_x\", \"weight_y\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tables\n",
    "df = (df_visit\n",
    "    .merge(df_screen, on=\"subject_identifier\", how=\"left\")\n",
    "    .merge(df_consent, on=\"subject_identifier\", how=\"left\")\n",
    "    .merge(df_rft, on=\"subject_visit_id\", how=\"left\")\n",
    "    .merge(df_weight, on=\"subject_visit_id\", how=\"left\")\n",
    "    .sort_values(by=[\"subject_identifier\", \"visit_datetime\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b2d = df.groupby('subject_identifier')['visit_datetime'].agg(visit_datetime_baseline=('min'), visit_datetime_endline=('max'))\n",
    "df = (df\n",
    "    .merge(df_b2d, on=\"subject_identifier\", how=\"left\")\n",
    "    .merge(df_rando[[\"subject_identifier\", \"assignment\", \"allocation\", \"allocated_datetime\"]], on=\"subject_identifier\", how=\"left\")\n",
    "    .sort_values(by=[\"subject_identifier\"]).reset_index(drop=True)\n",
    "    .reset_index(drop=True)\n",
    "      )\n",
    "df[\"days_on_study\"] = (df[\"visit_datetime_endline\"] - df[\"visit_datetime_baseline\"]).dt.days\n",
    "df[\"days_since_baseline\"] = (df[\"visit_datetime\"] - df[\"visit_datetime_baseline\"]).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc age in years\n",
    "df[\"age_in_years\"] = (df['visit_datetime'] - df['dob'])/pd.Timedelta(days=365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_since_baseline\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = (\n",
    "    df[[\"subject_identifier\", \"weight_imputed\", \"days_since_baseline\", \"assignment\", \"gender\", \"age_in_years\"]]\n",
    "    .copy()\n",
    "    .dropna()\n",
    "    .sort_values([\"subject_identifier\", \"days_since_baseline\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_model[\"subject_identifier\"] = df_model[\"subject_identifier\"].astype(str)\n",
    "df_model.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\n",
    "    # formula='weight_imputed ~ days_since_baseline + C(assignment) + C(gender) + age_in_years',\n",
    "    # formula='weight_imputed ~ days_since_baseline + C(assignment) + C(gender) + I(age_in_years**2)',\n",
    "    formula='weight_imputed ~ days_since_baseline * C(gender) + C(assignment)',\n",
    "    data=df_model,\n",
    "    groups=df_model['subject_identifier'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = df[df['days_since_baseline'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_purposeful = df_baseline[df_baseline['selection_method'] == 'purposeful']['weight_imputed']\n",
    "weight_random = df_baseline[df_baseline['selection_method'] == 'random']['weight_imputed']\n",
    "ttest_weight = stats.ttest_ind(weight_purposeful, weight_random, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Purposeful: {weight_purposeful.mean():.2f}\")\n",
    "print(f\"Mean Random:     {weight_random.mean():.2f}\")\n",
    "print(f\"T-test P-value:  {ttest_weight.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "purposeful = df_baseline[df_baseline['selection_method'] == 'purposeful']['age_in_years']\n",
    "random = df_baseline[df_baseline['selection_method'] == 'random']['age_in_years']\n",
    "ttest_result = stats.ttest_ind(purposeful, random, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"age_in_years\")\n",
    "print(f\"Mean Purposeful: {purposeful.mean():.2f}\")\n",
    "print(f\"Mean Random:     {random.mean():.2f}\")\n",
    "print(f\"T-test P-value:  {ttest_result.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_screen.select_dtypes([\"int64\", \"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [\n",
    "\"weight_scr\",\n",
    "\"creatinine_value\",\n",
    "\"egfr_value\",\n",
    "\"weight\",\n",
    "\"weight_baseline_imputed\",\n",
    "\"days_on_study\",\n",
    "\"age_in_years\",\n",
    "]\n",
    "result_text = []\n",
    "for col in cols:\n",
    "    purposeful = df_baseline[df_baseline['selection_method'] == 'purposeful'][col]\n",
    "    random = df_baseline[df_baseline['selection_method'] == 'random'][col]\n",
    "    ttest_result = stats.ttest_ind(purposeful, random, equal_var=False)\n",
    "    result_text.append(\n",
    "        f\"{col}\\n\"\n",
    "        f\"purposeful: {len(purposeful)}\\n\"\n",
    "        f\"random: {len(random)}\\n\"\n",
    "        f\"Mean Purposeful: {purposeful.mean():.2f}\\n\"\n",
    "        f\"Mean Random:     {random.mean():.2f}\\n\"\n",
    "        f\"T-test P-value:  {ttest_result.pvalue:.4f}\\n\"\n",
    "    )\n",
    "print(\"\\n\\n\".join(result_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gender\")\n",
    "print(f\"Mean Purposeful: {purposeful.mean():.2f}\")\n",
    "print(f\"Mean Random:     {random.mean():.2f}\")\n",
    "print(f\"T-test P-value:  {ttest_result.pvalue:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate eGFR\n",
    "def calculate_egfr(s):\n",
    "    if not s[\"creatinine_value\"]:\n",
    "        return pd.NA\n",
    "    else:\n",
    "        obj = EgfrCockcroftGault(\n",
    "            gender=s[\"gender\"],\n",
    "            age_in_years=s[\"age_in_years\"],\n",
    "            weight=s[\"weight\"],\n",
    "            creatinine_value=s[\"creatinine_value\"],\n",
    "            creatinine_units=MICROMOLES_PER_LITER,\n",
    "        )\n",
    "    return obj.value\n",
    "\n",
    "df[\"egfr_value_recalc\"] = pd.to_numeric(df.apply(lambda r: calculate_egfr(r), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categorical column `egfr_stage` using KIDGO\n",
    "bins = [0, 15, 30, 45, 60, 90, 200]\n",
    "labels = ['G5', 'G4', 'G3b', 'G3a', 'G2', 'G1']\n",
    "df['egfr_stage'] = pd.cut(\n",
    "    df['egfr_value_recalc'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False, # [a, b) -> G4 is [15, 30) -> 15.0 is G4, but 30.0 is G3b.\n",
    "    include_lowest=True # (0) is included in the first bin (G5)\n",
    ")\n",
    "kdigo_order = ['G1', 'G2', 'G3a', 'G3b', 'G4', 'G5']\n",
    "df['egfr_stage'] = pd.Categorical(\n",
    "    df['egfr_stage'],\n",
    "    categories=kdigo_order,\n",
    "    ordered=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"creatinine_grade\"] = df.creatinine_grade.apply(lambda x: \"\" if pd.isna(x) else x )\n",
    "df[\"egfr_abnormal\"] = df.egfr_abnormal.apply(lambda x: \"\" if pd.isna(x) else x )\n",
    "df[\"egfr_reportable\"] = df.egfr_reportable.apply(lambda x: \"\" if pd.isna(x) else x )\n",
    "df[\"egfr_grade\"] = df.egfr_grade.apply(lambda x: \"\" if pd.isna(x) else x )\n",
    "\n",
    "# recalc grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as CSV\n",
    "df.to_csv(data_folder / \"egfr_202510\", \"egfr.csv\", sep=\"|\", index=False, encoding=\"utf8\")\n",
    "\n",
    "# export as STATA\n",
    "df.to_stata(data_folder / \"egfr_202510\", \"egfr.dta\", version=118, write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numericals(df, *numerical_cols):\n",
    "    # Determine plot size (optional, but good for multiple plots)\n",
    "    num_plots = len(numerical_cols)\n",
    "    cols = 3  # Columns per figure\n",
    "    rows = (num_plots + cols - 1) // cols\n",
    "\n",
    "    # Create a figure to hold all subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "    axes = axes.flatten() # Flatten the 2D array of axes for easy indexing\n",
    "\n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        ax = axes[i]\n",
    "\n",
    "        sns.histplot(\n",
    "                data=df,\n",
    "                x=col,\n",
    "                kde=True,  # This tells Seaborn to draw the smoothing line\n",
    "                ax=ax,\n",
    "                bins=20,\n",
    "                stat='density' # Normalize the histogram height to match the KDE scale\n",
    "            )\n",
    "\n",
    "        # Plot KDE (Kernel Density Estimate) - requires calculation or a library like seaborn\n",
    "        # For simplicity with matplotlib only, we'll focus on the histogram.\n",
    "        # If using seaborn: sns.histplot(df[col], kde=True, ax=ax)\n",
    "\n",
    "        upper_limit = df[col].quantile(0.99)\n",
    "        plt.xlim(\n",
    "            df[col].min(),  # Start at the minimum value\n",
    "            upper_limit     # End at the 99th percentile\n",
    "        )\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Density')\n",
    "        # ax.grid(axis='y', alpha=0.3)\n",
    "        ax.grid(axis='y', alpha=0.5)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_plots, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('all_numeric_distributions.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df, category_column, category_order,  title='Distribution of Categories'):\n",
    "    \"\"\"Generates a bar plot for the specified categorical column.\"\"\"\n",
    "\n",
    "    plot_order = category_order\n",
    "    x_label = 'eGFR KDIGO Stage'\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "\n",
    "    # 2. Use seaborn.countplot for easy counting and plotting\n",
    "    ax = sns.countplot(\n",
    "        data=df,\n",
    "        x=category_column,\n",
    "        order=plot_order, # Use the defined or derived order for the x-axis\n",
    "        # palette='viridis',\n",
    "        # hue=category_column,\n",
    "        # legend=False,\n",
    "    )\n",
    "\n",
    "    # 3. Add counts and percentages on top of the bars for clarity\n",
    "    total = len(df)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if pd.notna(height): # Check for NaN if the category was empty\n",
    "            ax.annotate(\n",
    "                f'{int(height)}\\n({height/total:.1%})', # Show count and percentage\n",
    "                (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                xytext=(0, 5),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "\n",
    "    # 4. Final plot customizations\n",
    "    # ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(x_label, fontsize=12)\n",
    "    ax.set_ylabel('Subjects (count)', fontsize=12)\n",
    "\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numericals(df, 'creatinine_value', 'weight', 'weight_imputed', 'age_in_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['egfr_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_distribution(df.query(\"egfr_stage in @kdigo_order\"), 'egfr_stage', kdigo_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weight_change(df, change_column='weight_change'):\n",
    "    \"\"\"Plots the distribution of weight change with a clear zero reference.\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Use sns.histplot to plot the distribution with a KDE curve\n",
    "    ax = sns.histplot(\n",
    "        data=df,\n",
    "        x=change_column,\n",
    "        kde=True, # Overlay a smooth distribution line\n",
    "        bins=20,  # Adjust bins as needed for your data granularity\n",
    "        stat='count' # Show raw counts on the y-axis\n",
    "    )\n",
    "\n",
    "    # Add a vertical line at x=0 to clearly separate gain and loss\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='No Change (0)')\n",
    "\n",
    "    # Add shading to distinguish loss and gain areas (Optional, but very clear)\n",
    "    # Get the minimum and maximum change values for shading range\n",
    "    min_val = df[change_column].min()\n",
    "    max_val = df[change_column].max()\n",
    "\n",
    "    # Shade the Loss Area (left of 0)\n",
    "    ax.axvspan(min_val, 0, color='salmon', alpha=0.15, label='Weight Loss')\n",
    "\n",
    "    # Shade the Gain Area (right of 0)\n",
    "    ax.axvspan(0, max_val, color='skyblue', alpha=0.15, label='Weight Gain')\n",
    "\n",
    "    # Customize labels and title\n",
    "    # ax.set_title('Weight Change (Final - Initial)', fontsize=16)\n",
    "    ax.set_xlabel('Weight Change (kg )', fontsize=12)\n",
    "    ax.set_ylabel('Subjects (Count)', fontsize=12)\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('weight_change_distribution.png')\n",
    "\n",
    "    # Print summary statistics for context\n",
    "    num_gain = len(df[df[change_column] > 0])\n",
    "    num_loss = len(df[df[change_column] < 0])\n",
    "    num_total = len(df)\n",
    "\n",
    "    print(f\"Total Subjects: {num_total}\")\n",
    "    print(f\"Subjects Gaining Weight: {num_gain} ({num_gain/num_total:.1%})\")\n",
    "    print(f\"Subjects Losing Weight: {num_loss} ({num_loss/num_total:.1%})\")\n",
    "    print(f\"Mean Change: {df[change_column].mean():.2f}\")\n",
    "\n",
    "\n",
    "# Example of how you would call this function:\n",
    "# visualize_weight_change(df, change_column='weight_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weight_change(df, change_column='weight_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weight_change(df.query(\"egfr_stage in @kdigo_order\"), change_column='weight_change')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
